title:  Vision to Dynamics 
slug: project-url-slug  # For generating URLs/filenames
featured_image: /assets/imgs/project_imgs/dynamicsData.png

members:
  - name: Robert Collins
    image: /assets/imgs/people_thumbnails/Robert_T._Collins.jpg
    link: https://www.lipsum.com/
    role: Principal Investigator  # Optional
    institution: Pennsylvania State University

  - name: Yanxi Liu
    image: /assets/imgs/people_thumbnails/Yanxi_Liu.jpg
    link: https://www.lipsum.com/
    institution: Pennsylvania State University

  - name: Keaton Kraiger
    image: /assets/imgs/people_thumbnails/Keaton_Kraiger.jpg
    link: https://www.lipsum.com/
    institution: Pennsylvania State University

  - name: Skanda Bharadwaj
    image: /assets/imgs/people_thumbnails/Skanda_Bharadwaj.jpg
    link: https://www.lipsum.com/
    institution: Pennsylvania State University

  - name: John Challis
    image: /assets/imgs/people/John_Challis.jpg
    link: https://www.lipsum.com/
    role: Collaborator
    institution: Pennsylvania State University

  - name: Chris Funk 
    image: /assets/imgs/people/Chris_funk.png
    link: https://www.lipsum.com/
    role: Collaborator
    institution: Kitware

  - name: Jesse Scott 
    image: /assets/imgs/people/Jesse_Scott.jpg
    link: https://www.lipsum.com/
    role: Collaborator



description: |
  "Pose stability analysis is the key to understanding locomotion and control of body equilibrium, with applications in numerous fields such as kinesiology, medicine, and robotics. In biomechanics, Center of Pressure (CoP) is used in studies of human postural control and gait. We propose a novel approach to learn CoP from pose of a human body to aid stability analysis, learning foot pressure heatmaps (dynamics) from 2D human pose (kinematics) derived from video. We validated our learned results on a collection of long (5min +) choreographed Taiji (Tai Chi) sequences of multiple subjects with synchronized foot pressure and video data. Cross-subject validation results show promising performance, significantly outperforming the baseline methods. Furthermore, we demonstrate that our computation of center of pressure (CoP) approaches the expectations of corresponding lab-based measurements. "

# media:
  # images:
  #   - path: path/to/image1.jpg
  #     caption: Optional caption
  #   - path: path/to/image2.jpg
  # videos:
  #   - url: https://youtube.com/watch?v=xxx
  #     thumbnail: path/to/thumb.jpg
  #   - url: path/to/local/video.mp4
  
publications:
  - title: A Light-Weight Contrastive Approach for Aligning Human Pose Sequences
    link: https://arxiv.org/abs/2303.04244
    thumbnail: /assets/imgs/paper_thumbs/Lightweight.png

  - title: "Image-Based Stability Quantification"
    link: https://ieeexplore.ieee.org/document/9968276
    thumbnail: /assets/imgs/paper_thumbs/Image-based_stability.gif

  - title: "Dynamic Stability Monitoring of Complex Human Motion Sequences via Precision Computer Vision"
    link: https://etda.libraries.psu.edu/catalog/24465jus121
    thumbnail: /assets/imgs/paper_thumbs/Jesse_Diss.png 

  - title: Image-based Stability Quantification
    link: https://arxiv.org/abs/2206.11443
    thumbnail: /assets/imgs/paper_thumbs/img-based-stability-quant-arxiv.png

  - title: "From Image to Stability: Learning Dynamics from Human Pose"
    link: https://www.researchgate.net/publication/343139766_From_Image_to_Stability_Learning_Dynamics_from_Human_Pose
    thumbnail: /assets/imgs/paper_thumbs/learning_dynamics.png

datasets:
  - name: PSUTMM-100 Dataset
    image: /assets/imgs/project_imgs/psu-tmm100_source.gif
    description: "<br>The PSU Taiji MultiModal (PSU-TMM100) Dataset contains 100 Taiji motion sequences, 24-form Simplified Taiji-Quan, aka Tai Chi, performed by 10 human subjects. The dataset includes time-synchronized measurements: 
    <br>
    - motion capture markers and body joints recorded using Vicon Nexus 2.6.1
    <br>
    - foot pressure recorded using Tekscan F-scan 7.0 insole sensors \
    <br>
    - 1080p video from two views recorded using Vicon Nexus 2.6.1 
    <br>
    Additionally, OpenPose and HRNet pose detection networks networks are applied on both video views to generate 2D and triangulated 3D vision-based joints estimates.
    "
    url: "https://forms.office.com/r/ceCgdJGkE7"
    citation: "@inproceedings{Scott2020,<br>
      title = {From Image to Stability: Learning Dynamics from Human Pose},<br>
      author = {Scott, Jesse and Ravichandran, Bharadwaj and Funk, Christopher and Collins, Robert T. and Liu, Yanxi},<br>
      booktitle = {Computer Vision -- ECCV 2020},<br>
      pages = {536--554},<br>
      isbn = {978-3-030-58592-1},<br>
      year = {2020},<br>
      editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},<br>
      publisher = {Springer International Publishing},<br>
      address = {Cham},<br>
      doi = {10.1007/978-3-030-58592-1_32},<br>
    }"
    
funding:
  - agency: Penn State College of Engineering Dean's Office
    award: 
    url: 

  - agency: NSF
    award: "IIS-1218729"
    url: 

  - agency: NSF
    award: "IIS-190931"
    url: